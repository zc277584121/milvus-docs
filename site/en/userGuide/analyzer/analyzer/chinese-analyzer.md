# Chineseâ€‹

The `chinese`** **analyzer is designed specifically to handle Chinese text, providing effective segmentation and tokenization.â€‹

### Definitionâ€‹{#definitionâ€‹}

The `chinese` analyzer consists of:â€‹

- **Tokenizer**: Uses the `jieba` tokenizer to segment Chinese text into tokens based on vocabulary and context. For more information, refer to [â€‹Jieba](https://zilliverse.feishu.cn/wiki/JGURwBQNOijp2DkspFFctbAGnLh).â€‹

- **Filter**: Uses the `cnalphanumonly` filter to remove tokens that contain any non-Chinese characters. For more information, refer to [â€‹Cnalphanumonly](https://zilliverse.feishu.cn/wiki/R3r7wFHUbi8KxUk2t2FcUXoJnic).â€‹

The functionality of the `chinese` analyzer is equivalent to the following custom analyzer configuration:â€‹

```Python
analyzer_params = {â€‹
    "tokenizer": "jieba",â€‹
    "filter": ["cnalphanumonly"]â€‹
}â€‹

```

### Configurationâ€‹{#configurationâ€‹}

To apply the `chinese` analyzer to a field, simply set `type` to `chinese` in `analyzer_params`.â€‹

```Python
analyzer_params = {â€‹
    "type": "chinese",â€‹
}â€‹

```

:::info[ğŸ“˜ Notesâ€‹]

The `chinese` analyzer does not accept any optional parameters.â€‹

:::

### Example outputâ€‹{#example-outputâ€‹}

Hereâ€™s how the `chinese` analyzer processes text.â€‹

**Original text**:â€‹

```Python
"Milvus æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„å‘é‡æ•°æ®åº“ï¼"â€‹

```

**Expected output**:â€‹

```Python
["Milvus", "æ˜¯", "ä¸€ä¸ª", "é«˜æ€§", "æ€§èƒ½", "é«˜æ€§èƒ½", "å¯", "æ‰©å±•", "çš„", "å‘é‡", "æ•°æ®", "æ®åº“", "æ•°æ®åº“"]â€‹

```
